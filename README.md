# DCoI
**Dense Captioning of Images (Final Year Project)**

**Itâ€™s so easy for us, as human beings, to just have a glance at a picture and describe it in an appropriate language. But, can you write a computer program that takes an image as input and produces a relevant caption as output? **

Automatically describing the content of an image using properly formed English sentences is a fundamental problem in Artificial Intelligence(AI) that connects Computer Vision(CV) and Natural Language Processing(NLP). The description should not only capture the objects contained in the image, but it must also express how they relate to each other as well as the attributes and activities they are involved in. 

In recent years, with the rapid development of artificial intelligence, image captioning has gradually attracted the attention of many researchers in the field of artificial intelligence and has become an interesting and arduous task. Image captioning, automatically generating natural language descriptions according to the content observed in an image, is an important part of scene understanding, which combines the knowledge of computer vision and natural language processing. The application of image caption is extensive and significant, for example, the realization of human-computer interaction.

Image captioning has various applications such as recommendations in editing applications, usage in virtual assistants, for image indexing, for visually impaired persons, for social media, and several other natural language processing applications. Recently, deep learning methods have achieved state-of-the-art results on examples of this problem. It has been demonstrated that deep learning models are able to achieve optimum results in the field of caption generation problems. Instead of requiring complex data preparation or a pipeline of specifically designed models, a single end-to-end model can be defined to predict a caption, given a photo. 

Problem Definition:
Dense Image Captioning task describes the objects within an image by identifying them and their surroundings and establishing a relationship between them. This project requires a system making use of computer vision to both find regions and describe them in natural language. The images are passed through a Convolutional neural network to identify the region features. These features then form the input for the Recurrent neural network, which generates the captions for the regions encompassing the relationships between the objects.

