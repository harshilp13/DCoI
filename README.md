# DCoI
Dense Captioning of Images (Final Year Project)

Itâ€™s so easy for us, as human beings, to just have a glance at a picture and describe it in an appropriate language. But, can you write a computer program that takes an image as input and produces a relevant caption as output? 

Automatically describing the content of an image using properly formed English sentences is a fundamental problem in Artificial Intelligence(AI) that connects Computer Vision(CV) and Natural Language Processing(NLP). The description should not only capture the objects contained in the image, but it must also express how they relate to each other as well as the attributes and activities they are involved in. 

Dense Image Captioning task describes the objects within an image by identifying them and their surroundings and establishing a relationship between them. This project requires a system making use of computer vision to both find regions and describe them in natural language. The images are passed through a Convolutional neural network to identify the region features. These features then form the input for the Recurrent neural network, which generates the captions for the regions encompassing the relationships between the objects.


